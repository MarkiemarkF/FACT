{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file /home/anna/anaconda3/envs/fact_env/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /home/anna/anaconda3/envs/fact_env/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /home/anna/anaconda3/envs/fact_env/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from test_fair_clustering import main\n",
    "import argparse\n",
    "import os\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"outputs\"\n",
    "CSV_NAME = \"results.csv\"\n",
    "\n",
    "lambdas = {\n",
    "    \"Synthetic\": {\n",
    "        \"kmedian\": 10,\n",
    "        \"kmeans\": 10,\n",
    "        # \"ncut\": 10,\n",
    "    }, \n",
    "    \"Synthetic-unequal\": {\n",
    "        \"kmedian\": 10,\n",
    "        \"kmeans\": 10,\n",
    "        # \"ncut\": 10,\n",
    "    }, \n",
    "    \"Adult\": {\n",
    "        \"kmedian\": 9000,\n",
    "        \"kmeans\": 9000,\n",
    "        # \"ncut\": 10,\n",
    "    }, \n",
    "    \"Bank\": {\n",
    "        \"kmedian\": 9000,\n",
    "        \"kmeans\": 6000,\n",
    "        # \"ncut\": 40,\n",
    "    }, \n",
    "    \"CensusII\": {\n",
    "        \"kmedian\": 500000,\n",
    "        \"kmeans\": 500000,\n",
    "        # \"ncut\": 100,\n",
    "    }\n",
    "}\n",
    "\n",
    "n_runs = {\n",
    "    \"Synthetic\": 30, \n",
    "    \"Synthetic-unequal\": 30, \n",
    "    \"Adult\": 20,\n",
    "    \"Bank\": 20,\n",
    "    \"CensusII\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(seed=1, dataset=\"Synthetic-unequal\", cluster_option=\"ncut\", lmbda=10):\n",
    "    args = argparse.Namespace()\n",
    "    \n",
    "    args.plot_option_clusters_vs_lambda = True\n",
    "    args.plot_option_fairness_vs_clusterE = False\n",
    "    args.plot_option_balance_vs_clusterE = False\n",
    "    args.plot_option_convergence = False\n",
    "    args.lmbda_tune = False\n",
    "\n",
    "    args.seed = seed\n",
    "    args.dataset = dataset\n",
    "    args.cluster_option = cluster_option\n",
    "    args.lmbda = lmbda    \n",
    "\n",
    "    working_dir = os.getcwd()\n",
    "    args.data_dir = os.path.join(working_dir, \"data\")\n",
    "    args.output_path = os.path.join(working_dir, OUTPUT_FOLDER)\n",
    "    return args\n",
    "\n",
    "def make_csv(dir_path, csv_path, fieldnames):\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    if os.path.isfile(csv_path):\n",
    "        with open(csv_path, \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            if len([row for row in reader]) > 0:\n",
    "                return\n",
    "\n",
    "    with open(csv_path, \"w\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "def run_main(args, csv_name=CSV_NAME):\n",
    "    results = main(args, logging=False, seedable=True)\n",
    "\n",
    "    save_dict = {\n",
    "        \"dataset\": args.dataset,\n",
    "        \"N\": results['N'],\n",
    "        \"J\": results['J'],\n",
    "        \"lmbda\": args.lmbda,\n",
    "        \"Objective\": results[\"clustering energy (Objective)\"],\n",
    "        \"fairness error\": results[\"fairness error\"],\n",
    "        \"balance\": results[\"balance\"],\n",
    "        \"cluster_option\": args.cluster_option,\n",
    "        \"time\": results[\"time\"],\n",
    "        \"seed\": args.seed,\n",
    "        \"lmbda_tune\": args.lmbda_tune,\n",
    "        \"K\": results['K'],        \n",
    "    }\n",
    "\n",
    "    csv_path = os.path.join(args.output_path, csv_name)\n",
    "    fieldnames = save_dict.keys()\n",
    "    make_csv(args.output_path, csv_path, fieldnames)\n",
    "    with open(csv_path, \"a\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames)\n",
    "        writer.writerow(save_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_entry(args, row):\n",
    "    for key in [\"dataset\", \"lmbda\", \"cluster_option\", \"lmbda_tune\"]:\n",
    "        if str(getattr(args, key)) != row[key]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_same_options(csv_name, args):\n",
    "    entries = []\n",
    "    csv_path = os.path.join(args.output_path, csv_name)\n",
    "    with open(csv_path, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if compare_entry(args, row):\n",
    "                entries.append(row)\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enough results for these settings\n",
      "enough results for these settings\n",
      "enough results for these settings\n",
      "enough results for these settings\n",
      "enough results for these settings\n",
      "enough results for these settings\n",
      "enough results for these settings\n",
      "enough results for these settings\n",
      "enough results for these settings\n",
      "enough results for these settings\n"
     ]
    }
   ],
   "source": [
    "for dataset in lambdas:\n",
    "    for cluster_option in lambdas[dataset]:\n",
    "        lmbda = lambdas[dataset][cluster_option]\n",
    "\n",
    "        args = get_args(dataset=dataset, cluster_option=cluster_option, lmbda=lmbda)\n",
    "        existing_entries = find_same_options(CSV_NAME, args)\n",
    "        n = n_runs[dataset] - len(existing_entries)\n",
    "\n",
    "        if n < 1:\n",
    "            print(\"enough results for these settings\")\n",
    "            continue\n",
    "\n",
    "        seeds = [int(entry[\"seed\"]) for entry in existing_entries]\n",
    "        seeds.append(0)\n",
    "        next_seed = max(seeds) + 1\n",
    "        for seed in range(next_seed, next_seed + n):\n",
    "            args.seed = seed\n",
    "            print()\n",
    "            run_main(args, CSV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Synthetic\n",
      "\n",
      "KMEDIAN\n",
      "Objective            M = 289.08     SD = 2.03\n",
      "fairness error       M = 0.82     SD = 1.05\n",
      "balance              M = 0.34     SD = 0.21\n",
      "\n",
      "KMEANS\n",
      "Objective            M = 203.66     SD = 2.55\n",
      "fairness error       M = 2.43     SD = 1.47\n",
      "balance              M = 0.27     SD = 0.44\n",
      "\n",
      "\n",
      "Synthetic-unequal\n",
      "\n",
      "KMEDIAN\n",
      "Objective            M = 174.82     SD = 0.00\n",
      "fairness error       M = 0.00     SD = 0.00\n",
      "balance              M = 0.33     SD = 0.00\n",
      "\n",
      "KMEANS\n",
      "Objective            M = 169.15     SD = 28.20\n",
      "fairness error       M = 0.25     SD = 0.74\n",
      "balance              M = 0.30     SD = 0.10\n",
      "\n",
      "\n",
      "Adult\n",
      "\n",
      "KMEDIAN\n",
      "Objective            M = 17763.41     SD = 244.70\n",
      "fairness error       M = 0.01     SD = 0.00\n",
      "balance              M = 0.42     SD = 0.01\n",
      "\n",
      "KMEANS\n",
      "Objective            M = 10175.81     SD = 165.40\n",
      "fairness error       M = 0.01     SD = 0.00\n",
      "balance              M = 0.40     SD = 0.01\n",
      "\n",
      "\n",
      "Bank\n",
      "\n",
      "KMEDIAN\n",
      "Objective            M = 20087.08     SD = 264.69\n",
      "fairness error       M = 0.04     SD = 0.01\n",
      "balance              M = 0.17     SD = 0.00\n",
      "\n",
      "KMEANS\n",
      "Objective            M = 9604.38     SD = 242.81\n",
      "fairness error       M = 0.08     SD = 0.00\n",
      "balance              M = 0.17     SD = 0.00\n",
      "\n",
      "\n",
      "CensusII\n",
      "\n",
      "KMEDIAN\n",
      "Objective            M = 1746850.32     SD = 11858.69\n",
      "fairness error       M = 0.02     SD = 0.00\n",
      "balance              M = 0.75     SD = 0.04\n",
      "\n",
      "KMEANS\n",
      "Objective            M = 2050042.77     SD = 1466011.14\n",
      "fairness error       M = 39.05     SD = 55.17\n",
      "balance              M = 0.46     SD = 0.33\n"
     ]
    }
   ],
   "source": [
    "# Fetch results\n",
    "for dataset in lambdas:\n",
    "    print(f\"\\n\\n{dataset}\")\n",
    "    for cluster_option in lambdas[dataset]:\n",
    "        print(\"\\n\"+cluster_option.upper())\n",
    "        lmbda = lambdas[dataset][cluster_option]\n",
    "\n",
    "        args = get_args(dataset=dataset, cluster_option=cluster_option, lmbda=lmbda)\n",
    "        existing_entries = find_same_options(CSV_NAME, args)\n",
    "        \n",
    "        if len(existing_entries) < 1:\n",
    "            print(\"no data yet\")\n",
    "            continue\n",
    "\n",
    "        entry = existing_entries[0]\n",
    "        # name = f\"{dataset} (N = {entry['N']}, J = {entry['J']}, lmbda = {lmbda})\"\n",
    "\n",
    "        keys = [\"Objective\", \"fairness error\", \"balance\"]\n",
    "        for key in keys:\n",
    "            data = [float(entry[key]) for entry in existing_entries]\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "\n",
    "            print(f\"{key}{' '*(20-len(key))} M = {mean:.2f}     SD = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_main(get_args())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cc03dcd2e2df7f8793d069ea863b6d1996a0b7026a80ee0313ee24cbfa610e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
