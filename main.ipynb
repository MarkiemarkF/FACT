{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_fair_clustering import main\n",
    "import argparse\n",
    "import os\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"outputs\"\n",
    "CSV_NAME = \"results.csv\"\n",
    "\n",
    "lambdas = {\n",
    "    \"Synthetic\": {\n",
    "        \"kmedian\": 10,\n",
    "        \"kmeans\": 10,\n",
    "        # \"ncut\": 10,\n",
    "    }, \n",
    "    \"Synthetic-unequal\": {\n",
    "        \"kmedian\": 10,\n",
    "        \"kmeans\": 10,\n",
    "        # \"ncut\": 10,\n",
    "    }, \n",
    "    \"Adult\": {\n",
    "        \"kmedian\": 9000,\n",
    "        \"kmeans\": 9000,\n",
    "        # \"ncut\": 10,\n",
    "    }, \n",
    "    \"Bank\": {\n",
    "        \"kmedian\": 9000,\n",
    "        \"kmeans\": 6000,\n",
    "        # \"ncut\": 40,\n",
    "    }, \n",
    "    \"CensusII\": {\n",
    "        \"kmedian\": 500000,\n",
    "        \"kmeans\": 500000,\n",
    "        # \"ncut\": 100,\n",
    "    }\n",
    "}\n",
    "\n",
    "n_runs = {\n",
    "    \"Synthetic\": 30, \n",
    "    \"Synthetic-unequal\": 30, \n",
    "    \"Adult\": 20,\n",
    "    \"Bank\": 20,\n",
    "    \"CensusII\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(seed=1, dataset=\"Synthetic-unequal\", cluster_option=\"ncut\", lmbda=10):\n",
    "    args = argparse.Namespace()\n",
    "    \n",
    "    args.plot_option_clusters_vs_lambda = True\n",
    "    args.plot_option_fairness_vs_clusterE = False\n",
    "    args.plot_option_balance_vs_clusterE = False\n",
    "    args.plot_option_convergence = False\n",
    "    args.lmbda_tune = False\n",
    "\n",
    "    args.seed = seed\n",
    "    args.dataset = dataset\n",
    "    args.cluster_option = cluster_option\n",
    "    args.lmbda = lmbda    \n",
    "\n",
    "    working_dir = os.getcwd()\n",
    "    args.data_dir = os.path.join(working_dir, \"data\")\n",
    "    args.output_path = os.path.join(working_dir, OUTPUT_FOLDER)\n",
    "    return args\n",
    "\n",
    "def make_csv(dir_path, csv_path, fieldnames):\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    if os.path.isfile(csv_path):\n",
    "        with open(csv_path, \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            if len([row for row in reader]) > 0:\n",
    "                return\n",
    "\n",
    "    with open(csv_path, \"w\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "def run_main(args, csv_name=CSV_NAME):\n",
    "    results = main(args, logging=False, seedable=True)\n",
    "\n",
    "    save_dict = {\n",
    "        \"dataset\": args.dataset,\n",
    "        \"N\": results['N'],\n",
    "        \"J\": results['J'],\n",
    "        \"lmbda\": args.lmbda,\n",
    "        \"Objective\": results[\"clustering energy (Objective)\"],\n",
    "        \"fairness error\": results[\"fairness error\"],\n",
    "        \"balance\": results[\"balance\"],\n",
    "        \"cluster_option\": args.cluster_option,\n",
    "        \"time\": results[\"time\"],\n",
    "        \"seed\": args.seed,\n",
    "        \"lmbda_tune\": args.lmbda_tune,\n",
    "        \"K\": results['K'],        \n",
    "    }\n",
    "\n",
    "    csv_path = os.path.join(args.output_path, csv_name)\n",
    "    fieldnames = save_dict.keys()\n",
    "    make_csv(args.output_path, csv_path, fieldnames)\n",
    "    with open(csv_path, \"a\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames)\n",
    "        writer.writerow(save_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_entry(args, row):\n",
    "    for key in [\"dataset\", \"lmbda\", \"cluster_option\", \"lmbda_tune\"]:\n",
    "        if str(getattr(args, key)) != row[key]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_same_options(csv_name, args):\n",
    "    entries = []\n",
    "    csv_path = os.path.join(args.output_path, csv_name)\n",
    "    with open(csv_path, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if compare_entry(args, row):\n",
    "                entries.append(row)\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in lambdas:\n",
    "    for cluster_option in lambdas[dataset]:\n",
    "        lmbda = lambdas[dataset][cluster_option]\n",
    "\n",
    "        args = get_args(dataset=dataset, cluster_option=cluster_option, lmbda=lmbda)\n",
    "        existing_entries = find_same_options(CSV_NAME, args)\n",
    "        n = n_runs[dataset] - len(existing_entries)\n",
    "\n",
    "        if n < 1:\n",
    "            print(\"enough results for these settings\")\n",
    "            continue\n",
    "\n",
    "        seeds = [int(entry[\"seed\"]) for entry in existing_entries]\n",
    "        seeds.append(0)\n",
    "        next_seed = max(seeds) + 1\n",
    "        for seed in range(next_seed, next_seed + n):\n",
    "            args.seed = seed\n",
    "            print()\n",
    "            run_main(args, CSV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch results\n",
    "for dataset in lambdas:\n",
    "    print(f\"\\n\\n{dataset}\")\n",
    "    for cluster_option in lambdas[dataset]:\n",
    "        print(\"\\n\"+cluster_option.upper())\n",
    "        lmbda = lambdas[dataset][cluster_option]\n",
    "\n",
    "        args = get_args(dataset=dataset, cluster_option=cluster_option, lmbda=lmbda)\n",
    "        existing_entries = find_same_options(CSV_NAME, args)\n",
    "        \n",
    "        if len(existing_entries) < 1:\n",
    "            print(\"no data yet\")\n",
    "            continue\n",
    "\n",
    "        entry = existing_entries[0]\n",
    "        # name = f\"{dataset} (N = {entry['N']}, J = {entry['J']}, lmbda = {lmbda})\"\n",
    "\n",
    "        keys = [\"Objective\", \"fairness error\", \"balance\"]\n",
    "        for key in keys:\n",
    "            data = [float(entry[key]) for entry in existing_entries]\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "\n",
    "            print(f\"{key}{' '*(20-len(key))} M = {mean:.2f}     SD = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_main(get_args())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cc03dcd2e2df7f8793d069ea863b6d1996a0b7026a80ee0313ee24cbfa610e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('fact_vfc': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
