{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_fair_clustering import main\n",
    "import argparse\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"outputs\"\n",
    "DATA_FOLDER = \"data\"\n",
    "CSV_NAME = \"results.csv\"\n",
    "CSV_NAME_LIPSCHITZ = \"results_Lipschitz.csv\"\n",
    "\n",
    "DEFAULT_RUNS = 30\n",
    "DEFAULT_REPROD_L = 2.0\n",
    "MODES = [\"reprod\", \"lmbda_reprod\", \"Lipz_replic\"]\n",
    "settings = {\n",
    "    \"Synthetic\": {\n",
    "        \"kmedian\": {\n",
    "            \"reprod\":       {\"lmbda\": 10,       # got consistently bad results\n",
    "            },\n",
    "            \"lmbda_reprod\": {\"lmbda\": 600,\n",
    "            }\n",
    "        },\n",
    "        \"kmeans\": {\n",
    "            \"reprod\":       {\"lmbda\": 10,       # got optimal results only on some seeds\n",
    "            },\n",
    "            \"lmbda_reprod\": {\"lmbda\": 100,\n",
    "            }\n",
    "        },\n",
    "        \"ncut\": {\n",
    "            \"reprod\":       {\"lmbda\": 10,       # Successful reprod\n",
    "            }\n",
    "        },\n",
    "    }, \n",
    "    \"Synthetic-unequal\": {\n",
    "        \"kmedian\": {\n",
    "            \"reprod\":       {\"lmbda\": 10        # Successful reprod\n",
    "            }\n",
    "        },\n",
    "        \"kmeans\": {\n",
    "            \"reprod\":       {\"lmbda\": 10,       # seeds 20,22,24 are outliers. Successful reprod if left out.\n",
    "            }\n",
    "        }, \n",
    "        \"ncut\": {\n",
    "            \"reprod\":       {\"lmbda\": 10,       # Successful reprod\n",
    "            }\n",
    "        },\n",
    "    }, \n",
    "    \"Adult\": {\n",
    "        \"kmedian\": {\n",
    "            \"reprod\":       {\"lmbda\": 9000,\n",
    "            },\n",
    "            \"Lipz_replic\":  {\"lmbda\": 6500,\n",
    "                             \"Lipschitz\": 0.5,\n",
    "            }\n",
    "        },\n",
    "        \"kmeans\": {\n",
    "            \"reprod\":       {\"lmbda\": 9000,\n",
    "            },\n",
    "            \"Lipz_replic\":  {\"lmbda\": 9500,\n",
    "                             \"Lipschitz\": 1.0,\n",
    "            }\n",
    "        },\n",
    "        \"ncut\": {\n",
    "            \"reprod\":       {\"lmbda\": 10,       # Successful reprod\n",
    "                             \"Lipschitz\": 1.0,\n",
    "                             \"runs\": 5,\n",
    "            },\n",
    "            \"Lipz_replic\":  {\"lmbda\": 2,\n",
    "                             \"Lipschitz\": 0.00001,\n",
    "            }\n",
    "        }\n",
    "    }, \n",
    "    \"Bank\": {\n",
    "        \"kmedian\": {\n",
    "            \"reprod\":       {\"lmbda\": 9000,\n",
    "            },\n",
    "            \"Lipz_replic\":  {\"lmbda\": 9000,\n",
    "                             \"Lipschitz\": 1.0,\n",
    "            }\n",
    "        },\n",
    "        \"kmeans\": {\n",
    "            \"reprod\":       {\"lmbda\": 6000,\n",
    "            },\n",
    "            \"Lipz_replic\":  {\"lmbda\": 9000,\n",
    "                             \"Lipschitz\": 1.0,\n",
    "            }\n",
    "        },\n",
    "        \"ncut\": {\n",
    "            \"reprod\":       {\"lmbda\": 40,       # Successful reprod\n",
    "                             \"Lipschitz\": 1.0,\n",
    "                             \"runs\": 5,\n",
    "            },\n",
    "            \"Lipz_replic\":  {\"lmbda\": 1.2,\n",
    "                             \"Lipschitz\": 0.0001,\n",
    "            }\n",
    "        }\n",
    "    }, \n",
    "    # \"CensusII\": {\n",
    "    #     \"kmedian\": {\n",
    "    #         \"reprod\":       {\"lmbda\": 500000,\n",
    "    #                          \"runs\": 5,\n",
    "    #         }\n",
    "    #     },\n",
    "    #     \"kmeans\": {\n",
    "    #         \"reprod\":       {\"lmbda\": 500000,\n",
    "    #                          \"runs\": 5,\n",
    "    #         }\n",
    "    #     },\n",
    "    #     \"ncut\": {\n",
    "    #         \"reprod\":       {\"lmbda\": 100,\n",
    "    #                          \"Lipschitz\": 1.0,\n",
    "    #                          \"runs\": 1,\n",
    "    #         },\n",
    "    #         \"Lipz_replic\":  {\"lmbda\": 1,\n",
    "    #                          \"Lipschitz\": 0.00001,\n",
    "    #                          \"runs\": 1,\n",
    "    #         }\n",
    "    #     }\n",
    "    # }\n",
    "}\n",
    "\n",
    "n_runs_Lipschitz = 10\n",
    "Lipschitz_constants = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(seed=1, dataset=\"Synthetic-unequal\", cluster_option=\"ncut\", lmbda=None, lmbda_tune=False, Lipschitz=None, plot_bound_update=False):\n",
    "    \"\"\"\n",
    "    Return Namespace instance with passed and default arguments for main().\n",
    "\n",
    "    plot_bound_update:\n",
    "        if True, lets main() return a list of energies of a single bound update. Meant for checking convergence.\n",
    "    \"\"\"\n",
    "    args = argparse.Namespace()\n",
    "    \n",
    "    args.plot_option_clusters_vs_lambda = False     # Only available for the synthetic datasets\n",
    "    args.plot_option_fairness_vs_clusterE = True    # Only works when lmbda_tune == True\n",
    "    args.plot_option_balance_vs_clusterE = False    # Only works when lmbda_tune == True\n",
    "    args.plot_option_convergence = False\n",
    "    args.plot_bound_update = plot_bound_update      # Return a list of the energies of a single bound update\n",
    "    \n",
    "    args.reprod = False\n",
    "    args.kernel_type = None\n",
    "    args.kernel_args = [1, 2]\n",
    "\n",
    "    args.seed = seed\n",
    "    args.dataset = dataset\n",
    "    args.cluster_option = cluster_option\n",
    "    args.lmbda_tune = lmbda_tune\n",
    "\n",
    "    if lmbda:\n",
    "        args.lmbda = lmbda\n",
    "    else:\n",
    "        args.lmbda = settings[dataset][cluster_option][\"reprod\"][\"lmbda\"]\n",
    "    \n",
    "    if Lipschitz:\n",
    "        args.L = Lipschitz\n",
    "    elif \"Lipschitz\" in settings[dataset][cluster_option][\"reprod\"]:\n",
    "        args.L = settings[dataset][cluster_option][\"reprod\"][\"Lipschitz\"]\n",
    "    else:\n",
    "        args.L = DEFAULT_REPROD_L\n",
    "\n",
    "    working_dir = os.getcwd()\n",
    "    args.data_dir = os.path.join(working_dir, DATA_FOLDER)\n",
    "    args.output_path = os.path.join(working_dir, OUTPUT_FOLDER)\n",
    "    return args\n",
    "\n",
    "def make_csv(dir_path, csv_path, fieldnames):\n",
    "    \"\"\"\n",
    "    Make path and csv file with header if it doesn't exist yet. Otherwise do nothing.\n",
    "\n",
    "    dir_path:\n",
    "        full path to directory\n",
    "    csv_path:\n",
    "        full path to directory including the csv file\n",
    "    fieldnames:\n",
    "        fieldnames for the csv\n",
    "    \"\"\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    if os.path.isfile(csv_path):\n",
    "        with open(csv_path, \"r\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            if sum(1 for row in reader) > 0:\n",
    "                return\n",
    "\n",
    "    with open(csv_path, \"w\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "def run_main(args, csv_name=CSV_NAME):\n",
    "    \"\"\"\n",
    "    Run main and append results with settings to csv file.\n",
    "    File is automatically made if it doesn't exist yet.\n",
    "\n",
    "    csv_name:\n",
    "        just the filename of the csv, eg \"results.csv\"\n",
    "    \"\"\"\n",
    "    results = main(args, logging=False, seedable=True)\n",
    "\n",
    "    save_dict = {\n",
    "        \"dataset\": args.dataset,\n",
    "        \"N\": results['N'],                                      # Dataset size\n",
    "        \"J\": results['J'],                                      # Number of demographic groups (defined in dataset_load.py)\n",
    "        \"lmbda\": args.lmbda,\n",
    "        \"Objective\": results[\"clustering energy (Objective)\"],  # Discrete clustering energy\n",
    "        \"fairness error\": results[\"fairness error\"],\n",
    "        \"balance\": results[\"balance\"],\n",
    "        \"cluster_option\": args.cluster_option,\n",
    "        \"time\": results[\"time\"],                                # Time taken to finish this run\n",
    "        \"seed\": args.seed,\n",
    "        \"lmbda_tune\": args.lmbda_tune,                          \n",
    "        \"K\": results['K'],                                      # Number of clusters (defined in dataset_load.py)\n",
    "        \"L\": args.L,                                            # Lipschitz constant\n",
    "    }\n",
    "\n",
    "    csv_path = os.path.join(args.output_path, csv_name)\n",
    "    fieldnames = save_dict.keys()\n",
    "    make_csv(args.output_path, csv_path, fieldnames)\n",
    "    with open(csv_path, \"a\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames)\n",
    "        writer.writerow(save_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_entry(args, entry, keys):\n",
    "    \"\"\"\n",
    "    Compare args to an entry from the csv file and return True if they have the given keys in common:\n",
    "\n",
    "    args:\n",
    "        arguments that will be passed to main()\n",
    "    entry:\n",
    "        entry in the csv file made by run_main()\n",
    "    \"\"\"\n",
    "    for key in keys:\n",
    "        if str(getattr(args, key)) != entry[key]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_same_options(csv_name, args, keys=[\"dataset\", \"lmbda\", \"cluster_option\", \"lmbda_tune\", \"L\"]):\n",
    "    \"\"\"\n",
    "    Return entries from the csv file that have the same settings as the passed args, using compare_entry().\n",
    "\n",
    "    csv_name:\n",
    "        filename of the csv, eg \"results.csv\"\n",
    "    args:\n",
    "        arguments that will be passed to main()\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    csv_path = os.path.join(args.output_path, csv_name)\n",
    "    with open(csv_path, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if compare_entry(args, row, keys):\n",
    "                entries.append(row)\n",
    "    return entries\n",
    "\n",
    "def filter_outliers(entries, keys):\n",
    "    N = len(entries)\n",
    "    T_N = -norm.ppf(1/(4*N))\n",
    "    for key in keys:\n",
    "        sample = [float(entry[key]) for entry in entries]\n",
    "        mean = np.mean(sample)\n",
    "        std = np.std(sample)\n",
    "        for entry in entries:\n",
    "            distance = abs(float(entry[key]) - mean) / (std + 0.01*mean)\n",
    "            if distance >= T_N:\n",
    "                entry[\"outlier\"] = True\n",
    "    new_entries = []\n",
    "    for entry in entries:\n",
    "        if \"outlier\" in entry:\n",
    "            continue\n",
    "        new_entries.append(entry)\n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 1\n",
      "Cluster number for dataset Bank is 10\n",
      "Balance of the dataset 0.18501283697047496\n",
      "Number of points in the dataset 41108\n",
      "Demographic-probabilites: [0.11219227400992507, 0.2814050793032986, 0.6064026466867763]\n",
      "Demographic-numbers per group: [4612, 11568, 24928]\n",
      "Lipschitz constant: 0.0001\n",
      "Generating initial seeds\n",
      "Inside Lambda  1.2\n",
      "Inside Bound Update . . .\n",
      "[>           ] 1.5%Converged\n",
      "\n",
      " Elapsed Time in bound_update 7.610546799998701\n",
      "fairness_error = 0.3043\n",
      "compute energy\n",
      "fair clustering energy = 11.975456382884115\n",
      "clustering energy = 0.7419405338563667\n",
      "Elapsed so far: 7.841301799999201\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 1.2%Converged\n",
      "\n",
      " Elapsed Time in bound_update 6.0944054999999935\n",
      "fairness_error = 0.2609\n",
      "compute energy\n",
      "fair clustering energy = 11.908101791515136\n",
      "clustering energy = 0.7280019105447959\n",
      "Elapsed so far: 14.02172470000005\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 1.0%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.948619399998279\n",
      "fairness_error = 0.2352\n",
      "compute energy\n",
      "fair clustering energy = 11.864884038541753\n",
      "clustering energy = 0.7160700112304195\n",
      "Elapsed so far: 19.04828980000093\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 1.0%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.972171700002946\n",
      "fairness_error = 0.2184\n",
      "compute energy\n",
      "fair clustering energy = 11.830356909702049\n",
      "clustering energy = 0.7012948193063337\n",
      "Elapsed so far: 24.106890200000635\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.9%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.604524200000014\n",
      "fairness_error = 0.2040\n",
      "compute energy\n",
      "fair clustering energy = 11.798864992341647\n",
      "clustering energy = 0.6868045938736778\n",
      "Elapsed so far: 28.791935099998227\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.9%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.432334199998877\n",
      "fairness_error = 0.1928\n",
      "compute energy\n",
      "fair clustering energy = 11.769475674902942\n",
      "clustering energy = 0.6713963195293466\n",
      "Elapsed so far: 33.29953359999854\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.9%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.624970400000166\n",
      "fairness_error = 0.1840\n",
      "compute energy\n",
      "fair clustering energy = 11.746264282427381\n",
      "clustering energy = 0.6586797993783087\n",
      "Elapsed so far: 38.00031999999919\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.9%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.443158099998982\n",
      "fairness_error = 0.1776\n",
      "compute energy\n",
      "fair clustering energy = 11.72726348017716\n",
      "clustering energy = 0.6476012662795014\n",
      "Elapsed so far: 42.52031929999794\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.9%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.4965712999983225\n",
      "fairness_error = 0.1729\n",
      "compute energy\n",
      "fair clustering energy = 11.71052503302592\n",
      "clustering energy = 0.6364137265158778\n",
      "Elapsed so far: 47.09469230000104\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.9%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.793408699999418\n",
      "fairness_error = 0.1661\n",
      "compute energy\n",
      "fair clustering energy = 11.696399949824816\n",
      "clustering energy = 0.630254570015035\n",
      "Elapsed so far: 51.96860639999795\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.9%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.658112700002675\n",
      "fairness_error = 0.1636\n",
      "compute energy\n",
      "fair clustering energy = 11.687611928908897\n",
      "clustering energy = 0.6243311632673834\n",
      "Elapsed so far: 56.71474490000037\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.25208879999991\n",
      "fairness_error = 0.1605\n",
      "compute energy\n",
      "fair clustering energy = 11.681458531636574\n",
      "clustering energy = 0.6220051887041738\n",
      "Elapsed so far: 61.05167520000032\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.318387899998925\n",
      "fairness_error = 0.1587\n",
      "compute energy\n",
      "fair clustering energy = 11.676488146946681\n",
      "clustering energy = 0.6192079074053112\n",
      "Elapsed so far: 65.45619290000104\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.047093100001803\n",
      "fairness_error = 0.1560\n",
      "compute energy\n",
      "fair clustering energy = 11.671780681626682\n",
      "clustering energy = 0.6178255105297357\n",
      "Elapsed so far: 69.59492989999853\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 3.9144448000006378\n",
      "fairness_error = 0.1546\n",
      "compute energy\n",
      "fair clustering energy = 11.66823858397426\n",
      "clustering energy = 0.6155630040024249\n",
      "Elapsed so far: 73.59405609999885\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.004496000001382\n",
      "fairness_error = 0.1547\n",
      "compute energy\n",
      "fair clustering energy = 11.663568928158105\n",
      "clustering energy = 0.6110615814060623\n",
      "Elapsed so far: 77.68066159999944\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 3.9238777999999\n",
      "fairness_error = 0.1537\n",
      "compute energy\n",
      "fair clustering energy = 11.658322592239355\n",
      "clustering energy = 0.6070249394492038\n",
      "Elapsed so far: 81.69435130000056\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.0337085999999545\n",
      "fairness_error = 0.1517\n",
      "compute energy\n",
      "fair clustering energy = 11.65554244159561\n",
      "clustering energy = 0.6067654570772145\n",
      "Elapsed so far: 85.8114229999992\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 3.977557900001557\n",
      "fairness_error = 0.1507\n",
      "compute energy\n",
      "fair clustering energy = 11.652851308794528\n",
      "clustering energy = 0.6051590511204914\n",
      "Elapsed so far: 89.86894269999902\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.117178500000591\n",
      "fairness_error = 0.1496\n",
      "compute energy\n",
      "fair clustering energy = 11.65072599587949\n",
      "clustering energy = 0.6043613339096066\n",
      "Elapsed so far: 94.06571319999784\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 3.9021004999995057\n",
      "fairness_error = 0.1492\n",
      "compute energy\n",
      "fair clustering energy = 11.649298048566473\n",
      "clustering energy = 0.6034543241720041\n",
      "Elapsed so far: 98.04748449999897\n",
      "Inside ncut update\n",
      "Inside Bound Update . . .\n",
      "[>           ] 0.8%Converged\n",
      "\n",
      " Elapsed Time in bound_update 4.16989409999951\n",
      "fairness_error = 0.1485\n",
      "compute energy\n",
      "fair clustering energy = 11.648758398252582\n",
      "clustering energy = 0.6037479044234093\n",
      "......Job  done......\n",
      "102.42817110000033\n",
      "lambda = 1.2, \n",
      " fairness_error  0.15 and \n",
      " avg_balance =  0.18 \n",
      " min_balance =  0.14\n",
      "Best fairness_error 0.1485 |Error lambda =  1.2\n",
      "Best  Avg balance 0.1787 | Avg Balance lambda =  1.2\n",
      "Best  Min balance 0.1379 | Min Balance lambda =  1.2\n",
      "avg elapsed  102.42817110000033\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Execute one run\"\"\"\n",
    "run_main(get_args(\n",
    "    seed = 1, \n",
    "    dataset = \"Bank\",\n",
    "    cluster_option = \"ncut\", \n",
    "    lmbda = 1.2,\n",
    "    # lmbda_tune = True, \n",
    "    Lipschitz = 0.0001,     # Lipschitz constant\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run all settings with different seeds\"\"\"\n",
    "for mode in MODES:\n",
    "    for dataset in settings:\n",
    "        for cluster_option in settings[dataset]:\n",
    "            if mode not in settings[dataset][cluster_option]:\n",
    "                continue\n",
    "\n",
    "            lmbda = settings[dataset][cluster_option][mode][\"lmbda\"]\n",
    "            L = DEFAULT_REPROD_L             \n",
    "            if \"Lipschitz\" in settings[dataset][cluster_option][mode]:\n",
    "                L = settings[dataset][cluster_option][mode][\"Lipschitz\"]\n",
    "\n",
    "            args = get_args(dataset=dataset, cluster_option=cluster_option, lmbda=lmbda, Lipschitz=L)\n",
    "            existing_entries = find_same_options(CSV_NAME, args)\n",
    "\n",
    "            n_runs = DEFAULT_RUNS\n",
    "            if \"runs\" in settings[dataset][cluster_option][mode]:\n",
    "                n_runs = settings[dataset][cluster_option][mode][\"runs\"]\n",
    "                \n",
    "            if len(existing_entries) >= n_runs:\n",
    "                print(\"enough results for these settings\")\n",
    "                continue\n",
    "            n_todo = n_runs - len(existing_entries)\n",
    "\n",
    "            seeds = [int(entry[\"seed\"]) for entry in existing_entries]\n",
    "            seeds.append(0) # Make sure seeds is not empty\n",
    "            next_seed = max(seeds) + 1\n",
    "\n",
    "            for new_seed in range(next_seed, next_seed + n_todo):\n",
    "                args.seed = new_seed\n",
    "                print()\n",
    "                run_main(args, CSV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "REPROD\n",
      "\n",
      "  Synthetic\n",
      "\n",
      "    KMEDIAN\n",
      "    lmbda=10, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 289.08     SD = 2.03\n",
      "      fairness error       M = 0.82     SD = 1.05\n",
      "      balance              M = 0.34     SD = 0.21\n",
      "      time                 M = 4.78     SD = 1.65\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 289.08     SD = 2.03\n",
      "      fairness error       M = 0.82     SD = 1.05\n",
      "      balance              M = 0.34     SD = 0.21\n",
      "      time                 M = 4.78     SD = 1.65\n",
      "\n",
      "    KMEANS\n",
      "    lmbda=10, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 203.66     SD = 2.55\n",
      "      fairness error       M = 2.43     SD = 1.47\n",
      "      balance              M = 0.27     SD = 0.44\n",
      "      time                 M = 4.59     SD = 2.28\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 203.66     SD = 2.55\n",
      "      fairness error       M = 2.43     SD = 1.47\n",
      "      balance              M = 0.27     SD = 0.44\n",
      "      time                 M = 4.59     SD = 2.28\n",
      "\n",
      "    NCUT\n",
      "    lmbda=10, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 0.20     SD = 0.10\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.99     SD = 0.01\n",
      "      time                 M = 9.01     SD = 2.83\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 0.20     SD = 0.10\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.99     SD = 0.01\n",
      "      time                 M = 9.01     SD = 2.83\n",
      "\n",
      "  Synthetic-unequal\n",
      "\n",
      "    KMEDIAN\n",
      "    lmbda=10, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 174.82     SD = 0.00\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.33     SD = 0.00\n",
      "      time                 M = 3.72     SD = 0.90\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 174.82     SD = 0.00\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.33     SD = 0.00\n",
      "      time                 M = 3.72     SD = 0.90\n",
      "\n",
      "    KMEANS\n",
      "    lmbda=10, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 169.15     SD = 28.20\n",
      "      fairness error       M = 0.25     SD = 0.74\n",
      "      balance              M = 0.30     SD = 0.10\n",
      "      time                 M = 4.03     SD = 1.59\n",
      "\n",
      "      without outliers (3)\n",
      "      Objective            M = 159.75     SD = 0.00\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.33     SD = 0.00\n",
      "      time                 M = 3.99     SD = 1.66\n",
      "\n",
      "    NCUT\n",
      "    lmbda=10, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 0.02     SD = 0.03\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.32     SD = 0.01\n",
      "      time                 M = 4.14     SD = 2.32\n",
      "\n",
      "      without outliers (1)\n",
      "      Objective            M = 0.02     SD = 0.02\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.32     SD = 0.01\n",
      "      time                 M = 4.10     SD = 2.35\n",
      "\n",
      "  Adult\n",
      "\n",
      "    KMEDIAN\n",
      "    lmbda=9000, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 17901.76     SD = 311.53\n",
      "      fairness error       M = 0.01     SD = 0.00\n",
      "      balance              M = 0.42     SD = 0.01\n",
      "      time                 M = 44.61     SD = 23.25\n",
      "\n",
      "      without outliers (1)\n",
      "      Objective            M = 17887.87     SD = 307.59\n",
      "      fairness error       M = 0.01     SD = 0.00\n",
      "      balance              M = 0.42     SD = 0.01\n",
      "      time                 M = 44.31     SD = 23.59\n",
      "\n",
      "    KMEANS\n",
      "    lmbda=9000, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 10368.21     SD = 329.55\n",
      "      fairness error       M = 0.01     SD = 0.00\n",
      "      balance              M = 0.40     SD = 0.01\n",
      "      time                 M = 56.62     SD = 39.59\n",
      "\n",
      "      without outliers (1)\n",
      "      Objective            M = 10355.98     SD = 328.43\n",
      "      fairness error       M = 0.01     SD = 0.00\n",
      "      balance              M = 0.40     SD = 0.01\n",
      "      time                 M = 57.08     SD = 40.19\n",
      "\n",
      "    NCUT\n",
      "    lmbda=10, Lipschitz=1.0, runs=10\n",
      "      Objective            M = 0.78     SD = 0.02\n",
      "      fairness error       M = 0.08     SD = 0.02\n",
      "      balance              M = 0.36     SD = 0.03\n",
      "      time                 M = 3785.02     SD = 752.69\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 0.78     SD = 0.02\n",
      "      fairness error       M = 0.08     SD = 0.02\n",
      "      balance              M = 0.36     SD = 0.03\n",
      "      time                 M = 3785.02     SD = 752.69\n",
      "\n",
      "  Bank\n",
      "\n",
      "    KMEDIAN\n",
      "    lmbda=9000, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 20242.38     SD = 403.62\n",
      "      fairness error       M = 0.04     SD = 0.00\n",
      "      balance              M = 0.17     SD = 0.00\n",
      "      time                 M = 43.09     SD = 27.13\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 20242.38     SD = 403.62\n",
      "      fairness error       M = 0.04     SD = 0.00\n",
      "      balance              M = 0.17     SD = 0.00\n",
      "      time                 M = 43.09     SD = 27.13\n",
      "\n",
      "    KMEANS\n",
      "    lmbda=6000, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 9907.19     SD = 550.52\n",
      "      fairness error       M = 0.08     SD = 0.00\n",
      "      balance              M = 0.17     SD = 0.00\n",
      "      time                 M = 70.12     SD = 48.95\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 9907.19     SD = 550.52\n",
      "      fairness error       M = 0.08     SD = 0.00\n",
      "      balance              M = 0.17     SD = 0.00\n",
      "      time                 M = 70.12     SD = 48.95\n",
      "\n",
      "    NCUT\n",
      "    lmbda=40, Lipschitz=1.0, runs=5\n",
      "      Objective            M = 0.64     SD = 0.03\n",
      "      fairness error       M = 0.29     SD = 0.08\n",
      "      balance              M = 0.13     SD = 0.02\n",
      "      time                 M = 2835.36     SD = 532.08\n",
      "\n",
      "      without outliers (1)\n",
      "      Objective            M = 0.65     SD = 0.01\n",
      "      fairness error       M = 0.25     SD = 0.03\n",
      "      balance              M = 0.14     SD = 0.01\n",
      "      time                 M = 3087.35     SD = 190.78\n",
      "\n",
      "\n",
      "LMBDA_REPROD\n",
      "\n",
      "  Synthetic\n",
      "\n",
      "    KMEDIAN\n",
      "    lmbda=600, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 314.98     SD = 43.23\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.93     SD = 0.05\n",
      "      time                 M = 3.46     SD = 1.12\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 314.98     SD = 43.23\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 0.93     SD = 0.05\n",
      "      time                 M = 3.46     SD = 1.12\n",
      "\n",
      "    KMEANS\n",
      "    lmbda=100, Lipschitz=2.0, runs=30\n",
      "      Objective            M = 207.80     SD = 0.00\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 1.00     SD = 0.00\n",
      "      time                 M = 4.90     SD = 1.89\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 207.80     SD = 0.00\n",
      "      fairness error       M = 0.00     SD = 0.00\n",
      "      balance              M = 1.00     SD = 0.00\n",
      "      time                 M = 4.90     SD = 1.89\n",
      "\n",
      "  Synthetic-unequal\n",
      "\n",
      "  Adult\n",
      "\n",
      "  Bank\n",
      "\n",
      "\n",
      "LIPZ_REPLIC\n",
      "\n",
      "  Synthetic\n",
      "\n",
      "  Synthetic-unequal\n",
      "\n",
      "  Adult\n",
      "\n",
      "    KMEDIAN\n",
      "    lmbda=6500, Lipschitz=0.5, runs=30\n",
      "      Objective            M = 17531.71     SD = 205.50\n",
      "      fairness error       M = 0.01     SD = 0.00\n",
      "      balance              M = 0.40     SD = 0.00\n",
      "      time                 M = 23.31     SD = 10.15\n",
      "\n",
      "      without outliers (1)\n",
      "      Objective            M = 17513.10     SD = 182.47\n",
      "      fairness error       M = 0.01     SD = 0.00\n",
      "      balance              M = 0.40     SD = 0.00\n",
      "      time                 M = 23.46     SD = 10.29\n",
      "\n",
      "    KMEANS\n",
      "    lmbda=9500, Lipschitz=1.0, runs=30\n",
      "      Objective            M = 10103.20     SD = 130.60\n",
      "      fairness error       M = 0.01     SD = 0.00\n",
      "      balance              M = 0.40     SD = 0.00\n",
      "      time                 M = 43.02     SD = 20.50\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 10103.20     SD = 130.60\n",
      "      fairness error       M = 0.01     SD = 0.00\n",
      "      balance              M = 0.40     SD = 0.00\n",
      "      time                 M = 43.02     SD = 20.50\n",
      "\n",
      "    NCUT\n",
      "    lmbda=2, Lipschitz=1e-05, runs=30\n",
      "      Objective            M = 0.77     SD = 0.04\n",
      "      fairness error       M = 0.05     SD = 0.01\n",
      "      balance              M = 0.37     SD = 0.02\n",
      "      time                 M = 52.83     SD = 61.36\n",
      "\n",
      "      without outliers (1)\n",
      "      Objective            M = 0.77     SD = 0.04\n",
      "      fairness error       M = 0.05     SD = 0.01\n",
      "      balance              M = 0.37     SD = 0.01\n",
      "      time                 M = 53.37     SD = 62.34\n",
      "\n",
      "  Bank\n",
      "\n",
      "    KMEDIAN\n",
      "    lmbda=9000, Lipschitz=1.0, runs=30\n",
      "      Objective            M = 19743.99     SD = 341.91\n",
      "      fairness error       M = 0.05     SD = 0.01\n",
      "      balance              M = 0.17     SD = 0.00\n",
      "      time                 M = 31.04     SD = 9.39\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 19743.99     SD = 341.91\n",
      "      fairness error       M = 0.05     SD = 0.01\n",
      "      balance              M = 0.17     SD = 0.00\n",
      "      time                 M = 31.04     SD = 9.39\n",
      "\n",
      "    KMEANS\n",
      "    lmbda=9000, Lipschitz=1.0, runs=30\n",
      "      Objective            M = 9589.08     SD = 234.37\n",
      "      fairness error       M = 0.06     SD = 0.00\n",
      "      balance              M = 0.17     SD = 0.00\n",
      "      time                 M = 45.58     SD = 26.55\n",
      "\n",
      "      without outliers (0)\n",
      "      Objective            M = 9589.08     SD = 234.37\n",
      "      fairness error       M = 0.06     SD = 0.00\n",
      "      balance              M = 0.17     SD = 0.00\n",
      "      time                 M = 45.58     SD = 26.55\n",
      "\n",
      "    NCUT\n",
      "    lmbda=1.2, Lipschitz=0.0001, runs=30\n",
      "      Objective            M = 0.64     SD = 0.40\n",
      "      fairness error       M = 3.86     SD = 20.02\n",
      "      balance              M = 0.14     SD = 0.03\n",
      "      time                 M = 109.16     SD = 64.98\n",
      "\n",
      "      without outliers (1)\n",
      "      Objective            M = 0.56     SD = 0.06\n",
      "      fairness error       M = 0.14     SD = 0.02\n",
      "      balance              M = 0.14     SD = 0.01\n",
      "      time                 M = 112.83     SD = 62.95\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Fetch results from the csv\"\"\"\n",
    "for mode in MODES:\n",
    "    print(f\"\\n\\n{mode.upper()}\")\n",
    "    for dataset in settings:\n",
    "        print(f\"\\n  {dataset}\")\n",
    "        for cluster_option in settings[dataset]:\n",
    "            if mode not in settings[dataset][cluster_option]:\n",
    "                continue\n",
    "\n",
    "            print(\"\\n    \"+cluster_option.upper())\n",
    "\n",
    "            lmbda = settings[dataset][cluster_option][mode][\"lmbda\"]\n",
    "            L = DEFAULT_REPROD_L\n",
    "            if \"Lipschitz\" in settings[dataset][cluster_option][mode]:\n",
    "                L = settings[dataset][cluster_option][mode][\"Lipschitz\"]\n",
    "\n",
    "            args = get_args(dataset=dataset, cluster_option=cluster_option, lmbda=lmbda, Lipschitz=L)\n",
    "            existing_entries = find_same_options(CSV_NAME, args)\n",
    "            \n",
    "            if len(existing_entries) < 1:\n",
    "                print(\"no data yet\")\n",
    "                continue\n",
    "\n",
    "            entry = existing_entries[0]\n",
    "            print(f\"    lmbda={lmbda}, Lipschitz={entry['L']}, runs={len(existing_entries)}\")\n",
    "            \n",
    "            keys = [\"Objective\", \"fairness error\", \"balance\", \"time\"]\n",
    "            for key in keys:\n",
    "                data = [float(entry[key]) for entry in existing_entries]\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "\n",
    "                print(f\"      {key}{' '*(20-len(key))} M = {mean:.2f}     SD = {std:.2f}\")\n",
    "\n",
    "            filtered_entries = filter_outliers(existing_entries, [\"Objective\", \"fairness error\", \"balance\"])\n",
    "            print(f\"\\n      without outliers ({len(existing_entries)-len(filtered_entries)})\")\n",
    "            for key in keys:\n",
    "                data = [float(entry[key]) for entry in filtered_entries]\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "\n",
    "                print(f\"      {key}{' '*(20-len(key))} M = {mean:.2f}     SD = {std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Lipschitz_test(args, csv_name=CSV_NAME_LIPSCHITZ):\n",
    "    \"\"\"\n",
    "    Run bound update and append results with settings to csv file.\n",
    "    File is automatically made if it doesn't exist yet.\n",
    "    Logs of energy values by iteration are saved to .txt files as json, the path to which is saved in a csv field.\n",
    "\n",
    "    csv_name:\n",
    "        just the filename of the csv, eg \"results_Lipschitz.csv\"\n",
    "    \"\"\"\n",
    "    args.plot_bound_update = True\n",
    "    bound_energy_list, elapsed = main(args, logging=False, seedable=True)\n",
    "\n",
    "    list_dir = os.path.join(args.dataset, \"Lipschitz_energy_list_logs\")\n",
    "    os.makedirs(os.path.join(args.output_path, list_dir), exist_ok=True)\n",
    "    list_filepath = os.path.join(list_dir, f\"{args.cluster_option}__L={args.L}__lmb={args.lmbda}__seed={args.seed}.txt\")\n",
    "    list_filepath_full = os.path.join(args.output_path, list_filepath)\n",
    "    with open(list_filepath_full, \"w\") as f:\n",
    "        f.write(json.dumps(bound_energy_list))\n",
    "\n",
    "    save_dict = {\n",
    "        \"dataset\": args.dataset,\n",
    "        \"lmbda\": args.lmbda,\n",
    "        \"cluster_option\": args.cluster_option,\n",
    "        \"L\": args.L,                            # Lipschitz constant\n",
    "        \"convergence_iter\": len(bound_energy_list),\n",
    "        \"optimum\": min(bound_energy_list),\n",
    "        \"time\": elapsed,                        # Time taken to finish this run\n",
    "        \"seed\": args.seed,\n",
    "        \"energy_list_file\": list_filepath,        \n",
    "    }\n",
    "\n",
    "    csv_path = os.path.join(args.output_path, csv_name)\n",
    "    fieldnames = save_dict.keys()\n",
    "    make_csv(args.output_path, csv_path, fieldnames)\n",
    "    with open(csv_path, \"a\", newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames)\n",
    "        writer.writerow(save_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_Lipschitz_test(get_args(Lipschitz=0.0001, plot_bound_update=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run Lipschitz test for multiple settings\"\"\"\n",
    "\n",
    "for dataset in [\"Synthetic\", \"Synthetic-unequal\", \"Adult\", \"Bank\"]:\n",
    "    for cluster_option in [\"kmedian\", \"kmeans\", \"ncut\"]:\n",
    "        for L in Lipschitz_constants:\n",
    "\n",
    "            args = get_args(dataset=dataset, cluster_option=cluster_option, lmbda=1, Lipschitz=L, plot_bound_update=True)\n",
    "            existing_entries = find_same_options(CSV_NAME_LIPSCHITZ, args, keys=[\"dataset\", \"cluster_option\", \"L\"])\n",
    "\n",
    "            if len(existing_entries) >= n_runs_Lipschitz:\n",
    "                print(\"enough results for these settings\")\n",
    "                continue\n",
    "            n_todo = n_runs_Lipschitz - len(existing_entries)\n",
    "\n",
    "            seeds = [int(entry[\"seed\"]) for entry in existing_entries]\n",
    "            seeds.append(0) # Make sure seeds is not empty\n",
    "            next_seed = max(seeds) + 1\n",
    "\n",
    "            for new_seed in range(next_seed, next_seed + n_todo):\n",
    "                args.seed = new_seed\n",
    "                print()\n",
    "                run_Lipschitz_test(args, CSV_NAME_LIPSCHITZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_Lipschitz_convergence(save_path, energy_list_by_L, yscale_log=False):\n",
    "    \"\"\"Plot clustering objective by iteration for different Lipschitz constants\"\"\"\n",
    "    for L, lis in energy_list_by_L.items():\n",
    "        plt.plot(range(len(lis[\"mean\"])), lis[\"mean\"], label=f\"L = {L}\")\n",
    "        # plt.fill_between(range(len(lis[\"std\"])), lis[\"mean\"]+lis[\"std\"], lis[\"mean\"]-lis[\"std\"], alpha=.5)\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"fair objective\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    suffix = \"\"\n",
    "    if yscale_log:\n",
    "        plt.ylim(min(energy_list_by_L[2.0][\"mean\"]), np.max([max(lis[\"mean\"][1:]) for lis in energy_list_by_L.values()]))\n",
    "        plt.yscale('log')\n",
    "        suffix = \"_y-log\"\n",
    "    else:\n",
    "        plt.ylim(min(energy_list_by_L[2.0][\"mean\"]), max(energy_list_by_L[0.01][\"mean\"][1:]))\n",
    "    plt.xscale('log')\n",
    "    plt.savefig(save_path.format(suffix=suffix))\n",
    "    plt.close('all')\n",
    "\n",
    "def plot_Lipschitz_conv_iter(save_path, conv_iter_by_L, yscale_log=False):\n",
    "    pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fetch Lipschitz results from the csv and make plots\"\"\"\n",
    "for dataset in settings:\n",
    "    print(\"\\n\\n\"+dataset)\n",
    "    for cluster_option in settings[dataset]:\n",
    "        print(\"\\n  \"+cluster_option.upper())\n",
    "        energy_list_by_L = {}\n",
    "        complete = True\n",
    "        for L in Lipschitz_constants:\n",
    "            args = get_args(dataset=dataset, cluster_option=cluster_option, Lipschitz=L)\n",
    "            existing_entries = find_same_options(CSV_NAME_LIPSCHITZ, args, keys=[\"dataset\", \"cluster_option\", \"L\"])\n",
    "            \n",
    "            if len(existing_entries) < 1:\n",
    "                print(f\"no data yet on {dataset} with {cluster_option} at Lipshitz={L}\")\n",
    "                complete = False\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n    Lipschitz = {L}\")\n",
    "            keys = [\"convergence_iter\", \"optimum\", \"time\"]\n",
    "            for key in keys:\n",
    "                data = [float(entry[key]) for entry in existing_entries]\n",
    "                mean = np.mean(data)\n",
    "                std = np.std(data)\n",
    "\n",
    "                print(f\"    {key}{' '*(20-len(key))} M = {mean:.2f}     SD = {std:.2f}\")\n",
    "\n",
    "            energy_lists_by_run = []\n",
    "            for entry in existing_entries:\n",
    "                with open(os.path.join(args.output_path, entry[\"energy_list_file\"]), \"r\") as f:\n",
    "                    energy_lists_by_run.append(json.loads(f.read()))\n",
    "\n",
    "            max_len = max([int(entry[\"convergence_iter\"]) for entry in existing_entries])\n",
    "            energy_array_by_run = np.zeros((len(existing_entries), max_len))\n",
    "            for i, energy_list in enumerate(energy_lists_by_run):\n",
    "                last_value = energy_list[-1]\n",
    "                for iter in range(len(energy_list), max_len):\n",
    "                    energy_list.append(last_value)\n",
    "                energy_array_by_run[i] = energy_list\n",
    "                \n",
    "            energy_list_by_L[L] = {\n",
    "                # \"mean\": np.mean(energy_array_by_run, axis=1),\n",
    "                \"mean\": energy_array_by_run[0],\n",
    "                \"std\": np.std(energy_array_by_run, axis=1),\n",
    "            }\n",
    "\n",
    "        if complete:\n",
    "            save_dir = os.path.join(args.output_path, dataset)\n",
    "            save_path = os.path.join(save_dir, f\"{cluster_option}_\"+\"Lipschitz_plot{suffix}.png\")\n",
    "            plot_Lipschitz_convergence(save_path, energy_list_by_L)\n",
    "            plot_Lipschitz_convergence(save_path, energy_list_by_L, yscale_log=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5cc03dcd2e2df7f8793d069ea863b6d1996a0b7026a80ee0313ee24cbfa610e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('fact_vfc': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
